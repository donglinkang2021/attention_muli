{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data import load_data_train\n",
    "from attention import TransformerEncoder, TransformerDecoder\n",
    "from seq2seq import EncoderDecoder, train_seq2seq, predict_seq2seq, bleu\n",
    "\n",
    "def try_gpu(i=0):\n",
    "    \"\"\"\n",
    "    Return gpu(i) if exists, otherwise return cpu()\n",
    "    \"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "num_hiddens, num_blks, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 10\n",
    "lr, num_epochs, device = 0.005, 200, try_gpu()\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [32]\n",
    "\n",
    "train_iter, en_vocab, cn_vocab = load_data_train(batch_size, num_steps)\n",
    "\n",
    "# train en to cn\n",
    "\n",
    "encoder = TransformerEncoder(\n",
    "    len(en_vocab),\n",
    "    num_hiddens, \n",
    "    ffn_num_hiddens, \n",
    "    num_heads,\n",
    "    num_blks, \n",
    "    dropout\n",
    ")\n",
    "\n",
    "decoder = TransformerDecoder(\n",
    "    len(cn_vocab), \n",
    "    num_hiddens, \n",
    "    ffn_num_hiddens, \n",
    "    num_heads,\n",
    "    num_blks, \n",
    "    dropout\n",
    ")\n",
    "\n",
    "transformer = EncoderDecoder(\n",
    "    encoder, decoder\n",
    ")\n",
    "\n",
    "train_seq2seq(\n",
    "    transformer, \n",
    "    train_iter, \n",
    "    lr, \n",
    "    num_epochs, \n",
    "    cn_vocab, \n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "chis = ['我 走 了 。', '我 迷失 了 。', '他 很 冷 静 。', '我 回家 了 。']\n",
    "for eng, chi in zip(engs, chis):\n",
    "    translation = predict_seq2seq(\n",
    "        eng, \n",
    "        transformer, \n",
    "        en_vocab, \n",
    "        cn_vocab, \n",
    "        num_steps, \n",
    "        device\n",
    "    )\n",
    "    print(f'{eng} => {translation}, expect {chi}, bleu {bleu(translation, [chi], k=2) * 100:.1f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
